\part{Introduction to Deep Learning}
\chapter{Linear Regression}
\section{Supervised Learning}
\subsection{Outline}
\subsubsection{What is supervised learing?}
\textbf{Data:} input-output pairs\\

\textbf{Input:} features\\
\textbf{Output:} targets or labels\\
\textbf{Example of supervised learing: Linear Regression}\\


\section{Linear Regression}

\subsection{Regression accuracy}
\subsubsection{ERROR}
The measure of how far the data is from the fitted regression line.\\

\subsubsection{MAE}
\textbf{Meaned average Error}

\subsubsection{MSE}
\textbf{Meaned square Error}

\subsubsection{RMSE}
\textbf{Root meaned squared Error}

\subsubsection{RAE}

\subsubsection{RSE}

\subsubsection{R\textsuperscript{2}}
1-RSE
\subsection{Train/Test split evaluation approach}

\subsubsection{Test on a portion of train set}

Testset is a portion of the train set.

\textbf{Result:} 
\begin{itemize}
\item -- High "training accuracy"
\item -- Low "out-of-sample-accuracy"
\end{itemize}

\subsubsection{Train/Test Split}

Training Set and Testing Set a splitet


\textbf{Result:} 
\begin{itemize}
\item ++ More Accurate evaluation on out-of-sample accuracy
\item -- Highly depent on which dataset the data is trained and tested
\end{itemize}

\subsection{K-fold cross-validation}

Use 75\% to training dataset and 25\% to testing dataset
Accuracy = %average $(80% + 84% + 82% + 86%) = 83%$\\

\subsection{Evaluation Metrics in Regression Models}


\subsection{Multipe Linear Regression}

\textbf{Usecases}
\begin{itemize}
\item Independent variables effectivnes on prediction
\item Prediction impacts of changes
\end{itemize}





